# Building an LLM on your Laptop to Learn Faster

| Room | Time | Speakers |
|------|------|---------|
| 404 | 9:00 - 10:30 | Joe Houghes & Anthony Nocentino |

## Session Description

With the rise of LLMs (Large Language Models) and all of the amazing capabilities it can bring, tons of applications are being built which are based on huge LLM providers like OpenAI, Anthropic, AzureAI and Cohere.

One common assumption around many of these applications from common users, is that they are outside of the realm of what many of us could build ourselves. Fortunately, this is not the reality of our capabilities.

In this workshop to show how with we can build our own chatbot to speed up our learning through a little bit effort, the fantastic tech that is retrieval augmented generation (RAG), and a few components.

Not only will we walk through what these components do and how the interact, but we'll show everyone how we use them to construct an application similar to ChatPDF, but even simpler that we can run locally (or in a VM or container).

We'll then load up some documentation from PowerShell, PowerCLI, azcli, and maybe even PowerShell in a Month of Lunches to see how we can leverage this knowledge live, without taking the time to RTFM.

Seriously though, there is some huge power which comes from taking the time to understand how this type of tools works, and maybe giving yourself some shortcuts in using these tools, plus yourself and your peers having a new advantage in your day job - or just your personal learning.

Come join this workshop, let's learn a few things and build some cool tooling that you can use immediately. Hopefully this will launch you into some other projects as well.

## Notes

- Docker has built-in LLM support now
  - Docker may not have GPU access to run the LLM

## Links

- [GitHub Repo](https://github.com/nocentino/building-an-llm-on-your-laptop)
